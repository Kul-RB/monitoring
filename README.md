# Задание
Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

# Решение
1. Метрики ЦПУ, так как происходят вычичсления 
2. Метрики ОЗУ, для отслеживания утечки памяти
3. Метрики дисков, так как отчеты сохраняются на диск нужно знать сколько осталось памяти на машине
4. Healthcheck для проверки работоспособности программы
5. Метрики inodes так как отчетов может быть много, если закончились inode то сохранение файлов отчета прекратится 

# Задание
Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

# Решение
1. RAM - метрики использования оперативной памяти хоста
2. inodes - метрики индексации файлов
3. CPUla - среднее значение нагрузки процессора

Заключить с клиентами SLA, который будет включать в себя SLI для оценки работы сервиса и SLO для показателей к которому стремится компания. Для управления приложением необходимо учитывать среднее время между сбоями и среднее время на восстановление приложения

# Задание
Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

# Решение
Для сборов логов можно использовать Elastick Stack и Grafana Loki, на данный момент более доступна Grafana Loki для отправки логов из приложения можно использовать Serilog.

# Задание
Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

# Решение
Ошибка в том что мы не учитываем 1хх и 3хх ответы, которые не являются ошибками формула должна выглядеть так: (summ_1xx_requests + summ_2xx_requests + summ_3xx_requests)/summ_all_requests

# Задание
Опишите основные плюсы и минусы pull и push систем мониторинга

# Решение
PULL 
Плюсы:
1. Легче контролировать подлинность данных
2. Можно настроить единый proxy server до всех агентов с TLS
3. Упрощённая отладка получения данных с агентов
Минусы:
Для динамических машин нужен дополнительный оркестратор
Сложная настройка (для безопасности лучше настроить прокси, открытие портов для доступа и т.д.)
PUSH
Плюсы:
1. Упрощение репликации данных в разные системы мониторинга или их резервные копии
2. более гибкая настройка отправки пакетов данных с метриками
3. UDP — это менее затратный способ передачи данных, из-за чего может возрасти
производительность сбора метри
Минусы:
Много причин при недоступности хоста (упал агент, упал сервер, неполадки с сетью и т.д.)

# Задание
Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios
# Решение
1. Prometheus (push (PushGateway); pull)
2. TICK (push; pull (Kapasitor))
3. Zabbix (push (активный режим); pull(пассивный режим))
4. VictoriaMetrics (PUSH)
5. Nagios (PUSH), но как и у Zabbix есть пассивыный и активный режим

# Задание
Склонируйте себе репозиторий и запустите TICK-стэк, используя технологии docker и docker-compose.
В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (http://localhost:8888).

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим Z, например ./data:/var/lib:Z

# Решение
![image](https://github.com/Kul-RB/monitoring/assets/53901269/4203e9bf-2f96-426e-b67d-bdd5476232d0)

# Задание
Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.

Нажмите на кнопку Add a query
Изучите вывод интерфейса и выберите БД telegraf.autogen
В measurments выберите cpu->host->telegraf-getting-started, а в fields выберите usage_system. Внизу появится график утилизации cpu.
Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.
Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.

# Решение
![image](https://github.com/Kul-RB/monitoring/assets/53901269/f0053e59-faee-4c34-90dc-1b1148a3b253)

# Задание
Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

# Решение
![image](https://github.com/Kul-RB/monitoring/assets/53901269/cf9da6d7-d5f9-432e-b2c8-82009b5ac632)


